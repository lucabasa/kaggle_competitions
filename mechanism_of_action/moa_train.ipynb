{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.iterate import Iterator\n",
    "from source.train import run_training\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('data/raw/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/raw/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/raw/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/raw/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/raw/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 876)\n",
      "(3624, 876)\n",
      "(21948, 207)\n"
     ]
    }
   ],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train[[col for col in train if col not in target.columns or col == 'sig_id']]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucabasa/Git/kaggle_competitions/mechanism_of_action/moa/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 0\n",
    "EARLY_STOP = True\n",
    "\n",
    "hidden_size=1024\n",
    "\n",
    "train_args = {'train': folds, 'test': test, 'target_cols': target_cols, 'target': target,\n",
    "              'g_comp': 28, 'c_comp': 5, 'g_feat': GENES, 'c_feat': CELLS, 'pca_add': True, 'thr': 0.9, \n",
    "              'batch_size': BATCH_SIZE, 'hidden_size': hidden_size, 'device': DEVICE, \n",
    "              'early_stopping_steps': EARLY_STOPPING_STEPS, 'learning_rate': LEARNING_RATE, \n",
    "              'epochs': EPOCHS, 'weight_decay': WEIGHT_DECAY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = Iterator(train=train, test=test, target_cols=target_cols, \n",
    "                    seeds=[1903, 1881], \n",
    "                    n_folds=NFOLDS, train_func=run_training, train_args=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof, pred = iterator.it_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target_cols] = oof\n",
    "test[target_cols] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014628144289927201\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucabasa/Git/kaggle_competitions/mechanism_of_action/moa/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014620350834682704\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('data/raw/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/raw/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/raw/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/raw/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/raw/sample_submission.csv')\n",
    "\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train[[col for col in train if col not in target.columns or col == 'sig_id']]\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 0\n",
    "EARLY_STOP = True\n",
    "\n",
    "hidden_size=1024\n",
    "\n",
    "train_args = {'train': folds, 'test': test, 'target_cols': target_cols, 'target': target,\n",
    "              'g_comp': 28, 'c_comp': 5, 'g_feat': GENES, 'c_feat': CELLS, 'pca_add': True, 'thr': 0.4, \n",
    "              'batch_size': BATCH_SIZE, 'hidden_size': hidden_size, 'device': DEVICE, \n",
    "              'early_stopping_steps': EARLY_STOPPING_STEPS, 'learning_rate': LEARNING_RATE, \n",
    "              'epochs': EPOCHS, 'weight_decay': WEIGHT_DECAY}\n",
    "\n",
    "iterator = Iterator(train=train, test=test, target_cols=target_cols, \n",
    "                    seeds=[1903, 1881], \n",
    "                    n_folds=NFOLDS, train_func=run_training, train_args=train_args)\n",
    "\n",
    "oof, pred = iterator.it_seeds()\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = pred\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucabasa/Git/kaggle_competitions/mechanism_of_action/moa/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.014611888216730002\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('data/raw/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/raw/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/raw/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/raw/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/raw/sample_submission.csv')\n",
    "\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train[[col for col in train if col not in target.columns or col == 'sig_id']]\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 0\n",
    "EARLY_STOP = True\n",
    "\n",
    "hidden_size=1024\n",
    "\n",
    "train_args = {'train': folds, 'test': test, 'target_cols': target_cols, 'target': target,\n",
    "              'g_comp': 28, 'c_comp': 5, 'g_feat': GENES, 'c_feat': CELLS, 'pca_add': True, 'thr': 0.1, \n",
    "              'batch_size': BATCH_SIZE, 'hidden_size': hidden_size, 'device': DEVICE, \n",
    "              'early_stopping_steps': EARLY_STOPPING_STEPS, 'learning_rate': LEARNING_RATE, \n",
    "              'epochs': EPOCHS, 'weight_decay': WEIGHT_DECAY}\n",
    "\n",
    "iterator = Iterator(train=train, test=test, target_cols=target_cols, \n",
    "                    seeds=[1903, 1881], \n",
    "                    n_folds=NFOLDS, train_func=run_training, train_args=train_args)\n",
    "\n",
    "oof, pred = iterator.it_seeds()\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = pred\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucabasa/Git/kaggle_competitions/mechanism_of_action/moa/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass shuffle=False, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.01471371012115755\n"
     ]
    }
   ],
   "source": [
    "train_features = pd.read_csv('data/raw/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('data/raw/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('data/raw/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('data/raw/test_features.csv')\n",
    "sample_submission = pd.read_csv('data/raw/sample_submission.csv')\n",
    "\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]\n",
    "\n",
    "train = train[[col for col in train if col not in target.columns or col == 'sig_id']]\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=7)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "\n",
    "# HyperParameters\n",
    "\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 3e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 7\n",
    "EARLY_STOPPING_STEPS = 0\n",
    "EARLY_STOP = True\n",
    "\n",
    "hidden_size=1024\n",
    "\n",
    "train_args = {'train': folds, 'test': test, 'target_cols': target_cols, 'target': target,\n",
    "              'g_comp': 28, 'c_comp': 5, 'g_feat': GENES, 'c_feat': CELLS, 'pca_add': True, 'thr': 1.3, \n",
    "              'batch_size': BATCH_SIZE, 'hidden_size': hidden_size, 'device': DEVICE, \n",
    "              'early_stopping_steps': EARLY_STOPPING_STEPS, 'learning_rate': LEARNING_RATE, \n",
    "              'epochs': EPOCHS, 'weight_decay': WEIGHT_DECAY}\n",
    "\n",
    "iterator = Iterator(train=train, test=test, target_cols=target_cols, \n",
    "                    seeds=[1903, 1881], \n",
    "                    n_folds=NFOLDS, train_func=run_training, train_args=train_args)\n",
    "\n",
    "oof, pred = iterator.it_seeds()\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = pred\n",
    "\n",
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / target.shape[1]\n",
    "    \n",
    "print(\"CV log_loss: \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
