{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from source.clean import general_cleaner, drop_columns\n",
    "from source.transf_category import recode_cat, make_ordinal\n",
    "from source.transf_numeric import tr_numeric\n",
    "import source.transf_univ as dfp\n",
    "import source.utility as ut\n",
    "import source.report as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "df_train['Target'] = np.log1p(df_train.SalePrice)\n",
    "\n",
    "df_train = df_train[df_train.GrLivArea < 4500].copy().reset_index(drop=True)\n",
    "\n",
    "del df_train['SalePrice']\n",
    "\n",
    "train_set, test_set = ut.make_test(df_train, \n",
    "                                test_size=0.2, random_state=654, \n",
    "                                strat_feat='Neighborhood')\n",
    "\n",
    "y = train_set['Target'].copy()\n",
    "del train_set['Target']\n",
    "\n",
    "y_test = test_set['Target']\n",
    "del test_set['Target']\n",
    "\n",
    "folds = KFold(5, shuffle=True, random_state=541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_lasso = Pipeline([('fs', dfp.feat_sel('numeric')),\n",
    "                         ('imp', dfp.df_imputer(strategy='median')),\n",
    "                         ('transf', tr_numeric(lot=False, \n",
    "                                               bedroom=False, \n",
    "                                               SF_room=False))])\n",
    "\n",
    "\n",
    "cat_lasso = Pipeline([('fs', dfp.feat_sel('category')),\n",
    "                     ('imp', dfp.df_imputer(strategy='most_frequent')), \n",
    "                     ('ord', make_ordinal(['BsmtQual', 'KitchenQual', 'ExterQual', 'HeatingQC'], \n",
    "                                          extra_cols=['BsmtExposure', 'BsmtCond', 'ExterCond'],\n",
    "                                          include_extra='include')), \n",
    "                     ('recode', recode_cat()), \n",
    "                     ('dummies', dfp.dummify(drop_first=True))])\n",
    "\n",
    "\n",
    "processing_lasso = dfp.FeatureUnion_df(transformer_list=[('cat', cat_lasso),\n",
    "                                                 ('num', numeric_lasso)])\n",
    "\n",
    "lasso_pipe = Pipeline([('gen_cl', general_cleaner()),\n",
    "                       ('proc', processing_lasso),\n",
    "                       ('scaler', dfp.df_scaler(method='standard')),\n",
    "                       ('dropper', drop_columns(lasso=True)), \n",
    "                       ('lasso', Lasso(alpha=0.001, tol=0.005))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_forest = Pipeline([('fs', dfp.feat_sel('numeric')),\n",
    "                         ('imp', dfp.df_imputer(strategy='median')),\n",
    "                         ('transf', tr_numeric(SF_room=False,\n",
    "                                               bedroom=False, \n",
    "                                               lot=False))])\n",
    "\n",
    "\n",
    "cat_forest = Pipeline([('fs', dfp.feat_sel('category')),\n",
    "                     ('imp', dfp.df_imputer(strategy='most_frequent')), \n",
    "                     ('ord', make_ordinal(['BsmtQual', 'KitchenQual', 'ExterQual', 'HeatingQC'], \n",
    "                                          extra_cols=['BsmtExposure', 'BsmtCond', 'ExterCond'],\n",
    "                                          include_extra='include')), \n",
    "                     ('recode', recode_cat()), \n",
    "                     ('dummies', dfp.dummify(drop_first=True))])\n",
    "\n",
    "\n",
    "processing_forest = dfp.FeatureUnion_df(transformer_list=[('cat', cat_forest),\n",
    "                                                 ('num', numeric_forest)])\n",
    "\n",
    "forest_pipe = Pipeline([('gen_cl', general_cleaner()),\n",
    "                       ('proc', processing_forest),\n",
    "                       ('scaler', dfp.df_scaler(method='robust')),\n",
    "                       ('dropper', drop_columns(forest=True)), \n",
    "                       ('forest', RandomForestRegressor(n_estimators=1500, max_depth=30, \n",
    "                                                        max_features='sqrt',\n",
    "                                                        n_jobs=-1, random_state=32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.60557842, 11.82619678, 11.52454952, ..., 11.88873264,\n",
       "       12.09583506, 11.74783932])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_lasso = Pipeline([('scaler', dfp.df_scaler(method='standard')),\n",
    "                       ('dropper', drop_columns(lasso=True)), \n",
    "                       ('lasso', Lasso(alpha=0.001, tol=0.005))])\n",
    "\n",
    "short_forest = Pipeline([('scaler', dfp.df_scaler(method='robust')),\n",
    "                       ('dropper', drop_columns(forest=True)), \n",
    "                       ('forest', RandomForestRegressor(n_estimators=1500, max_depth=30, \n",
    "                                                        max_features='sqrt',\n",
    "                                                        n_jobs=-1, random_state=32))])\n",
    "\n",
    "start_pipe = Pipeline([('gen_cl', general_cleaner()), \n",
    "                     ('proc', processing_forest)])\n",
    "\n",
    "avg_pipe = Pipeline([('start', start_pipe), \n",
    "                     ('models', AveragingModels(models = (short_lasso, short_forest)))])\n",
    "\n",
    "\n",
    "avg_oof = ut.cv_score(train_set, y, folds, avg_pipe, imp_coef=False)\n",
    "\n",
    "avg_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1185\n",
      "MAE: 14874.2532\n"
     ]
    }
   ],
   "source": [
    "print(f'RMSE: {round(np.sqrt(mean_squared_error(y, avg_oof)), 4)}')\n",
    "print(f'MAE: {round(mean_absolute_error(np.expm1(y), np.expm1(avg_oof)), 4)}')\n",
    "\n",
    "rp.plot_predictions(train_set, y, avg_oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
